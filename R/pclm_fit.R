
#' Fit PCLM Models
#' 
#' This is an internal function used to estimate PCLM model. It is used by 
#' \code{\link{pclm}} and \code{\link{pclm2D}} functions
#' @inheritParams pclm
#' @inheritParams pclm.control
#' @param pclm.type Type of PCLM model. Options: \code{"1D", "2D"} for 
#' univariate and two-dimensional model respectively.
#' @keywords internal
pclm.fit <- function(x, y, nlast, offset, out.step, 
                     lambda, kr, deg, diff, max.iter, tol, pclm.type){
  # Some preparations
  ny    <- if (pclm.type == "1D") length(y) else ncol(y)
  CM    <- build_C_matrix(x, y, nlast, out.step, pclm.type)
  C     <- if (!is.null(offset)) CM$C %*% diag(as.vector(unlist(offset))) else CM$C
  BSB   <- build_B_spline_basis(x = list(CM$gx, 1:ny), kr, deg, diff, lambda, pclm.type)
  B     <- BSB$B
  P     <- BSB$P 
  y     <- as.vector(unlist(y))
  nx    <- dim(B)[2] 
  beta0 <- rep(log(sum(y) / length(y)), nx)
  eta   <- B %*% beta0
  gamma <- exp(eta)
  
  # Perform the iterations
  for (it in 1:max.iter) {
    gamma0 <- gamma
    mu     <- c(C %*% gamma)
    w      <- as.vector(mu)
    Q      <- (C * ((1 / mu) %*% t(gamma)) ) %*% B
    z      <- y - mu + C %*% (gamma * eta)
    QwQ    <- t(Q) %*% (w * Q) 
    QwQP   <- QwQ + P
    beta   <- solve(QwQP, t(Q) %*% z)
    eta    <- B %*% beta
    gamma  <- exp(eta)
    da     <- max(abs(gamma - gamma0))
    if (da < tol & it > 4) break
  }
  if (it == max.iter) warning("The maximal number of iteration has been reached. ",
                              "Maybe it is a good idea to increase it. ",
                              "See 'pclm.control'.", call. = F)
  # Regression diagnostics
  H     <- solve(QwQP, QwQ)
  trace <- sum(diag(H))
  ok    <- y > 0
  dev   <- 2 * sum(y[ok] * log(y[ok] / mu[ok]))
  AIC   <- dev + 2 * trace
  BIC   <- dev + log(length(y)) * trace
  fit   <- as.numeric(exp(eta))
  out   <- as.list(environment())
  return(out)
}

#' Compute Standard Errors and Confidence Intervals
#' @param X An object generated by pclm.fit
#' @inheritParams pclm
#' @keywords internal
pclm.confidence <- function(X, ci.level) {
  with(X, {
    H0    <- solve(QwQP)       # vcov matrix Bayesian approach
    H1    <- H0 %*% QwQ %*% H0 # vcov matrix sandwich estimator
    s.e.  <- sqrt(diag(B %*% H1 %*% t(B)))
    psi2  <- dev / (length(y) - trace) # overdispersion
    # Confidence intervals
    qn    <- qnorm(1 - ci.level/2)
    lower <- as.numeric(exp(eta - qn*s.e.))
    upper <- as.numeric(exp(eta + qn*s.e.))
    #output
    out <- list(s.e. = s.e., lower = lower, upper = upper)
    return(out)
  })
}


#' Optimize Smoothing Parameters
#' This function optimize searches of \code{lambda, kr} and \code{deg}. 
#' See \code{\link{pclm.control}} to see what is their meaning. 
#' The optimization process works in steps. Simultaneous optimization was 
#' tested and found inefficient. Methods tested: "Nelder-Mead" (optim) 
#' and "PORT routines" (nlminb).
#' @inheritParams pclm
#' @keywords internal
optimize.smoothing.par <- function(x, y, nlast, offset, out.step, 
                                   control, pclm.type) {
  with(control, {
    Par <- c(lambda, kr, deg)
    # Objective functions ---
    FN <- function(L, K, D) {
      L <- round(L, 2)
      print(c(L = L, K = K, D = D))
      pclm.fit(x, y, nlast, offset, out.step, lambda = L, kr = K, deg = D, 
               diff, max.iter, tol, pclm.type)[[paste(opt.method)]]
    }
    F_D <- function(x) FN(L = ifelse(is.na(Par[1]), 1, Par[1]), 
                          K = ifelse(is.na(Par[2]), 8, Par[2]), D = x)
    F_K <- function(x) FN(L = ifelse(is.na(Par[1]), 1, Par[1]), K = x, D = Par[3])
    F_L <- function(x) FN(L = exp(x), K = Par[2], D = Par[3])
    # ---
    if (is.na(deg)) { # Step 1. Find deg over integer values
      i      <- int.deg[1]:int.deg[2]
      res    <- apply(matrix(i), 1, F_D)
      Par[3] <- i[res == min(res)][1]
    }
    if (is.na(kr)) { # Step 2. Find kr over integer values
      i      <- int.kr[1]:int.kr[2]
      res    <- apply(matrix(i), 1, F_K)
      Par[2] <- i[res == min(res)][1]
    }
    if (is.na(lambda)) { # Step 3. Find lambda (continuos)
      opt    <- optimise(f = F_L, interval = log(int.lambda), tol = 0.01)
      Par[1] <- round(exp(opt$minimum), 2)
    }
    
    if (Par[1] == int.lambda[2]) {
      warning(paste0("'lambda' has reached the upper limit of ", int.lambda[2],
                    ". Maybe it is a good idea to extend interval. ",
                    "See 'int.lambda' argument in 'pclm.control'."), call. = F)
    } 
    return(Par)
  })
}


#' Build Composition Matrices
#' @inheritParams pclm.fit
#' @keywords internal
build_C_matrix <- function(x, y, nlast, out.step, pclm.type) {
  # Build C matrix in the age direction
  nx <- length(x)
  CA <- NULL
  if (!is.null(nx)) {
    gx       <- seq(min(x), max(x) + nlast - out.step, by = out.step)
    g.units  <- c(diff(x), nlast)/out.step
    g.number <- sum(g.units)
    CA       <- matrix(0, nrow = nx, ncol = g.number)
    r.names  <- paste0("[", x,",", c(x[-1], rev(x)[1] + nlast), ")")
    dimnames(CA) <- list(r.names, gx)
    xr       <- c(x[-1], max(x) + nlast)
    for (j in 1:nx) CA[j, which(gx >= x[j] & gx < xr[j])] = 1
  }
  # Build C matrix in the year direction
  C  <- CA
  CY <- NULL
  if (pclm.type == "2D") {
    ny <- ncol(y)
    CY <- diag(1, ncol = ny, nrow = ny) 
    dimnames(CY) <- list(1:ny, 1:ny)
    C  <- CY %x% CA
  }
  # Output
  out <- as.list(environment())
  return(out)
}


#' Construct B-spline basis
#' This is an internal function which constructs B-spline basis to be used in 
#' pclm estimation
#' @param x List containing the two numeric vectors for the abscissa of data.
#' @inheritParams pclm.fit
#' @examples 
#' \dontrun{
#' # check examples in build_C_matrix function
#' }
#' @seealso \code{\link{MortSmooth_bbase}}
#' @keywords internal
build_B_spline_basis <- function(x, kr, deg, diff, lambda, pclm.type) {
  vsn  <- 0.5 # very small number
  # B-spline basis for age
  X    <- x[[1]]
  ndx1 <- max(2, trunc(length(X)/kr)) # at least 2 knots
  BA   <- MortSmooth_bbase(x = X, xl = min(X - vsn), xr = max(X + vsn), 
                           ndx = ndx1, deg) 
  # B-spline basis for year
  Y    <- x[[2]]
  ndx2 <- max(2, trunc(length(Y)/kr))
  BY   <- MortSmooth_bbase(x = Y, xl = min(Y - vsn), xr = max(Y + vsn), 
                           ndx = ndx2, deg)
  # Penalties
  DA  <- diff(diag(ncol(BA)), diff = diff)
  DY  <- diff(diag(ncol(BY)), diff = diff)
  tDA <- t(DA) %*% DA
  tDY <- t(DY) %*% DY
  
  if (pclm.type == "1D") {
    B <- BA 
    P <- lambda * tDA
  } else {
    B  <- BY %x% BA
    P1 <- lambda * (diag(ncol(BY)) %x% tDA)
    P2 <- lambda * (tDY %x% diag(ncol(BA)))
    P  <- P1 + P2  
  } 
  # output
  out <- as.list(environment())
  return(out)
}


#' Create an additional bin with a small value at the end. 
#' Improves convergence.
#' @param i A list of input values corresponding to pclm or pclm2D
#' @param vy Numerical value of the bin created for 'y' input
#' @param vo Numerical values of the bin created for 'offset' input (if the case)
#' @keywords internal
create.artificial.bin <- function(i, vy = 1, vo = 1.01){
  with(i, {
    x     <- c(x, max(x) + nlast)
    nlast <- out.step
    L     <- !is.null(offset)
    
    if (is.vector(y)) {
      y <- c(y, vy)
      if (L) offset <- c(offset, vo)
    } else {
      y <- rbind(y, vy)
      if (L) offset <- rbind(offset, vo)
    }
    
    out  <- list(x = x, y = y, nlast = nlast, offset = offset)
    return(out)
  })
}


#' Delete from results the last group added artificially in pclm and pclm2D 
#' @param M A pclm.default object
#' @keywords internal
delete.artificial.bin <- function(M){
  n <- 1
  N <- 1:n
  
  f1 <- function(x) { # method 1 - delete groups and reallocate values
    A <- rev(rev(x)[-N])
    B <- sum(rev(x)[N] - n)
    B * (A/sum(A)) + A
  }
  f2 <- function(x) { # method 2 - delete groups
    rev(rev(x)[-N])
  }
  L = M$pclm.type == "1D"
  M$fit   <- with(M, if (L) f1(fit)   else apply(fit, 2, FUN = f1))
  M$lower <- with(M, if (L) f1(lower) else apply(lower, 2, FUN = f1))
  M$upper <- with(M, if (L) f1(upper) else apply(upper, 2, FUN = f1))
  M$s.e.  <- with(M, if (L) f1(s.e.)  else apply(s.e., 2, FUN = f2))
  return(M)
}


#' Map groups and borders
#' 
#' We assume no missing values between the bins
#' @inheritParams pclm
#' @keywords internal
map.bins <- function(x, nlast, out.step) {
  step  <- c(diff(x), nlast)
  xl    <- rev(rev(c(0, cumsum(step)))[-1]) + 1
  xr    <- xl + step - 1
  N     <- length(xl)
  delta <- x[1] - xl[1]
  bl    <- round(xl + delta, 3)
  br    <- c(bl[-1], xr[N] + 1 + delta)
  
  dnames <- list(c("left", "right"), rep("", N))
  breaks <- matrix(c(bl, br), nrow = 2, byrow = T, dimnames = dnames)
  loc    <- matrix(c(xl, xr), nrow = 2, byrow = T, dimnames = dnames)
  input  <- list(n = N, 
                 length = xr - xl + 1, 
                 names  = paste0("[", bl,",", br, ")"), 
                 breaks = breaks, 
                 location = loc)
  output <- NULL
  if (!is.null(out.step)) {
    X <- range(breaks)
    X <- seqlast(X[1], X[2], by = out.step)
    output <- map.bins(X, NULL, NULL)$input
  }
  
  out <- list(input = input, output = output)
  return(out)
}


#' Sequence function with last value
#' 
#' @inheritParams base::seq
#' @keywords internal 
seqlast <- function(from, to, by) 
{
  vec <- do.call(what = seq, args = list(from, to, by))
  if ( tail(vec, 1) != to ) {
    return(c(vec, to))
  } else {
    return(vec)
  }
}


#' Extract Fractional Part of a Number
#' @param x A numeric value, vector or matrix
#' @keywords internal
frac <- function(x) {
  x - trunc(x)
}


#' Check if 'nlast' needs to be adjusted in order to accommodate out.step
#' @inheritParams pclm
#' @keywords internal
validate.nlast <- function(x, nlast, out.step) {
  len <- max(x) - min(x) + nlast
  N   <- len/out.step
  if (frac(N) != 0) {
    n.bins <- round(N, 0)
    new.nlast <- n.bins * out.step - len + nlast
    vos <- suggest.valid.out.step(len)
    warning("'nlast' has been adjusted in order to obtain ", n.bins, 
            " bins of equal length as specified in 'out.step = ", out.step,
            "'. Now 'nlast = ", new.nlast, "'. The impact in results is insignificant.",
            " However, if the adjustment is not acceptable",
            " try out one of the following 'out.step' values: ", 
            paste(vos, collapse = ", "), ".", call. = F)
  } else {
    new.nlast <- nlast
  }
  return(new.nlast)
}

#' Suggest values of 'out.step' that do not require an adjustment of 'nlast'
#' @param len Interval length
#' @param increment Increment
#' @keywords internal
suggest.valid.out.step <- function(len, increment = 0.01) {
  o  <- seq(0.1, 1, by = increment)
  v  <- len/o
  tv <- trunc(v)
  o[v == tv]
}



